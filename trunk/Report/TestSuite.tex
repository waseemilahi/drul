% test suite part written by T. Bertin-Mahieux
% tb2332@columbia.edu (2008) PLT
%!TEX root =  Report.tex

\chapter{Test Suite}
In the section we present the test suite we built and used for the DruL 
project. We start in Section \ref{ts:overview} by showing the basic idea
and limits for our testing program. In Section \ref{ts:implem} we give details
about the implementation. Finally, we give samples tests in 
Section \ref{ts:samples} and explain what they test.



\section{Overview} \label{ts:overview}
We built two different testing functions in order to debug DruL and help is
maintainability: \textbf{LaunchTestParser} and \textbf{LaunchTest}. There
usage is very similar.

\textbf{LaunchTestParser}'s goal is to make sure every meaningful DruL code
passes throught the scanner and parser without errors. We do not make sure
that malformed DruL code is intercepted. The program passes a set of DruL code
samples to the interpreter, and report whether a message error was produced.
This sort of testing was very useful at the beginning of the project, but
was later replaced by the more general \textbf{LaunchTest}.

\textbf{LaunchTest} takes a set of DruL code samples, pass them to the
interpreter, and compares the output with some predefined output. Therefore,
we can test both cases that fail (by catching the error message) or that
correctly pass (by printing to the standard output).


\section{Implementation} \label{ts:implem}
We implemented the two above testing programs in Python. This scripting
language allows for rapid development and has an excellent packages for
handling files. A test file has to have a certain extension (\textit{.drultest})
and so does the desired output (\textit{.drultestout}).
The core of the testing programs, aside from finding the test files and passing
them to the interpreter, is a simple ``diff'' function. This ``diff'' tells
us if every line of two files are exactly the same or not.
Everything is recorded in a LOG, whose name encodes the date and time of the test.


\section{Sample tests} \label{ts:samples}
We present some typical tests for both the parser and the interpreter. In the
second case, we also give the desired output.

\subsection{Tests for DruL Parser}

/TestSuite/ParserTests/logicalORAND.drultest

\begin{lstlisting}[basicstyle=\color{red}\small]
a = 1;
b = 2;
(false || true && false);
(true && false || true);
(a || b && 3 || false && true);
(true || false) && ((false && true || true) || true);
\end{lstlisting}


/TestSuite/ParserTests/print.drultest
\begin{lstlisting}[basicstyle=\color{red}\small]
print ("1");
print(        "allo");
print ("yo!3748473222937`1-232-/._(*&^%$#@");
print(pattern(""));
print( pattern ("010111001"));
a = pattern("11110");
print (a);
b = 3;
print( b );
c = clip(a);
print (c);
\end{lstlisting}


\subsection{Tests for DruL}

/TestSuite/Tests/pattern12.drultest
\begin{lstlisting}[basicstyle=\color{red}\small]
p11 = map(pattern("1111"))
{
 if ($1.note() && $1.next(1).note() && $1.next(2).note() ) { return pattern("1")
; }
 else { return pattern("0"); }
};
print(p11); // should return 1100
\end{lstlisting}

/TestSuite/Tests/pattern12.drultestout

\begin{lstlisting}[basicstyle=\color{blue}\small]
1100
\end{lstlisting}


/TestSuite/Tests/clip2.drultest

\begin{lstlisting}[basicstyle=\color{red}\small]
instruments();
print(
        clip(
                pattern("1010")
        )
);
\end{lstlisting}

TestSuite/Tests/clip2.drultestout

\begin{lstlisting}[basicstyle=\color{blue}\small]
[
        hh_c:   1010
        sd_ac:
        bd:
        cowbell:
]
\end{lstlisting}




/TestSuite/Tests/assign5.drultest
\begin{lstlisting}[basicstyle=\color{red}\small]
p = pattern("10");
mapper pattern (p) {}
print("bad");
\end{lstlisting}

/TestSuite/Tests/assign5.drultestout
\begin{lstlisting}[basicstyle=\color{blue}\small]
Illegal assignment attempted on line 2: can't use keyword 'pattern' as a mapper name
\end{lstlisting}




\section{Conclusion}
The tests were designed by every team member, usually following the addition
of a feature to DruL interpreter. We tried to keep the tests small and specific
in order to better spot bugs. However, we also believe that ``the more the
better'', thus we cannot say that the test were wisely chosen. Fortunately,
there a smart-ass inside of everyone, and we do believe we tested most of
the possible flaws.

Our test suite (programs and test files) add up to $115$ cases and 
about $11000$ lines, almost
as much as DruL itself. However, we felt it was time well spent for two major
reasons:
\begin{itemize}
\item We did find bugs early in the coding process thanks to the test suite. One
particular example is the precedance for member functions that we had forgotten.
\item A complete test suite seems the only way to allow multiple programmers to
modify a file without breaking code written by someone else
\end{itemize}
Thus we believe that a complete test suite is an essential part of a compiler's
project and should be started before the actual language compiler.

